{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNq32/+YYT2eBrVfI0BBBxg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sara-Esm/callbackMNIST/blob/main/Copy_of_callbackMNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get current working directory\n",
        "current_dir = os.getcwd()\n",
        "\n",
        "# Append data/mnist.npz to the previous path to get the full path\n",
        "data_path = os.path.join(current_dir, \"data/mnist.npz\")\n",
        "\n",
        "# Discard test set\n",
        "(x_train, y_train), _ = tf.keras.datasets.mnist.load_data(path=data_path)\n",
        "\n",
        "# Normalize pixel values\n",
        "x_train = x_train / 255.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxgvIIXnY59_",
        "outputId": "7d3c43b7-23ef-4a5d-8f2a-6dbba2391abf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# grader-required-cell\n",
        "\n",
        "data_shape = x_train.shape\n",
        "\n",
        "print(f\"There are {data_shape[0]} examples with shape ({data_shape[1]}, {data_shape[2]})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JM9NR7uNgIgr",
        "outputId": "eca20111-5a25-4874-aa5b-f403c28ec8cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 60000 examples with shape (28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GRADED CLASS: myCallback\n",
        "### START CODE HERE\n",
        "\n",
        "# Remember to inherit from the correct class\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "    # Define the correct function signature for on_epoch_end\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if logs.get('accuracy') is not None and logs.get('accuracy') > 0.99:\n",
        "            print(\"\\nReached 99% accuracy so cancelling training!\")\n",
        "\n",
        "            # Stop training once the above condition is met\n",
        "            self.model.stop_training = True\n",
        "\n",
        "### END CODE HERE\n"
      ],
      "metadata": {
        "id": "_VzqkQA_imF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GRADED FUNCTION: train_mnist\n",
        "def train_mnist(x_train, y_train):\n",
        "    # Instantiate the callback class\n",
        "    callbacks = myCallback()\n",
        "\n",
        "    # Define the model\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Flatten(input_shape=(28, 28)),  # Flatten the input layer\n",
        "        tf.keras.layers.Dense(units=128, activation=tf.nn.relu),  # Dense hidden layer with ReLU activation\n",
        "        tf.keras.layers.Dense(units=10, activation=tf.nn.softmax)  # Output layer with softmax activation\n",
        "    ])\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # Fit the model for 10 epochs adding the callbacks\n",
        "    # and save the training history\n",
        "    history = model.fit(x_train, y_train, epochs=10, callbacks=[callbacks])\n",
        "\n",
        "    return history\n"
      ],
      "metadata": {
        "id": "VRvkWRkjmzKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# grader-required-cell\n",
        "\n",
        "hist = train_mnist(x_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BaC-fcawm3wy",
        "outputId": "251ce0ca-987a-4105-ab70-caae8eecbbfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2610 - accuracy: 0.9257\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1155 - accuracy: 0.9657\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0775 - accuracy: 0.9762\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0576 - accuracy: 0.9831\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0448 - accuracy: 0.9857\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0354 - accuracy: 0.9888\n",
            "Epoch 7/10\n",
            "1871/1875 [============================>.] - ETA: 0s - loss: 0.0276 - accuracy: 0.9917\n",
            "Reached 99% accuracy so cancelling training!\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0276 - accuracy: 0.9918\n"
          ]
        }
      ]
    }
  ]
}